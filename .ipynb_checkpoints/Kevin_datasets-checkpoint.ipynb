{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making pipelines \n",
    "Dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#import custom functions\n",
    "import Configure_Dataset\n",
    "import Impute\n",
    "import Normalize\n",
    "import Combine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C1', 'C2', 'C4', 'C7', '%_long_sentences', '%_long_words',\n",
       "       '%_positive_words', '%_negative_words', '%_uncertain_words', 'C3'',\n",
       "       'C5'', 'C6'', 'one_hot_Manufacturing', 'one_hot_Other',\n",
       "       'one_hot_Public Services', 'one_hot_Wholesale  Trade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, y1, y2 = Configure_Dataset.configure('Competition1_raw_data.xlsx')\n",
    "A.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Impute.impute_mean(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05392393 1.         0.74996242 ... 0.         0.         0.        ]\n",
      " [0.11988445 0.         0.58374777 ... 0.         0.         0.        ]\n",
      " [0.03851709 1.         0.71721278 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.04910929 0.         0.75525545 ... 0.         0.         0.        ]\n",
      " [0.03273953 1.         0.76253853 ... 1.         0.         0.        ]\n",
      " [0.13047665 1.         0.7327755  ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A = Normalize.minmax_scale(A)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Combine.combine(A, y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.749962</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.775008</td>\n",
       "      <td>0.541683</td>\n",
       "      <td>0.291209</td>\n",
       "      <td>0.313837</td>\n",
       "      <td>0.232749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035990</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.119884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583748</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.780245</td>\n",
       "      <td>0.473428</td>\n",
       "      <td>0.147348</td>\n",
       "      <td>0.398734</td>\n",
       "      <td>0.230548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717213</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.770640</td>\n",
       "      <td>0.721351</td>\n",
       "      <td>0.889070</td>\n",
       "      <td>0.183452</td>\n",
       "      <td>0.252440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.095811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714502</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.653036</td>\n",
       "      <td>0.718150</td>\n",
       "      <td>0.719433</td>\n",
       "      <td>0.222305</td>\n",
       "      <td>0.332049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033702</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499347</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>0.710854</td>\n",
       "      <td>0.405407</td>\n",
       "      <td>0.259462</td>\n",
       "      <td>0.351622</td>\n",
       "      <td>0.246559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.034602</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2         3         4         5         6         7  \\\n",
       "0  0.053924  1.0  0.749962  0.001671  0.775008  0.541683  0.291209  0.313837   \n",
       "1  0.119884  0.0  0.583748  0.000843  0.780245  0.473428  0.147348  0.398734   \n",
       "2  0.038517  1.0  0.717213  0.000238  0.770640  0.721351  0.889070  0.183452   \n",
       "3  0.095811  1.0  0.714502  0.000275  0.653036  0.718150  0.719433  0.222305   \n",
       "4  0.033702  1.0  0.499347  0.020605  0.710854  0.405407  0.259462  0.351622   \n",
       "\n",
       "          8    9        10        11   12   13   14   15  Y1  Y2  \n",
       "0  0.232749  1.0  0.035990  0.111111  1.0  0.0  0.0  0.0   0   1  \n",
       "1  0.230548  0.0  0.118042  0.000000  1.0  0.0  0.0  0.0   1   0  \n",
       "2  0.252440  0.0  0.031013  0.000000  1.0  0.0  0.0  0.0   1   0  \n",
       "3  0.332049  0.0  0.030315  0.000000  1.0  0.0  0.0  0.0   1   1  \n",
       "4  0.246559  1.0  0.034602  0.050000  0.0  0.0  1.0  0.0   0   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.5934; AUC 0.5953 \n",
      "Accuracy of classifier on test set: 0.59\n",
      "10-fold cross validation average accuracy of classifier: 0.604\n",
      "Confusion Matrix for Logistic Regression Classfier:\n",
      "[[42 32]\n",
      " [23 38]]\n",
      "Classification Report for Logistic Regression Classfier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.57      0.60        74\n",
      "          1       0.54      0.62      0.58        61\n",
      "\n",
      "avg / total       0.60      0.59      0.59       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    #Model building\n",
    "    clf = LogisticRegression()\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(predictors_y1, y1, test_size=0.2, random_state=123)\n",
    "    clf.fit(X1_train, y1_train)\n",
    "\n",
    "    y1_pred = clf.predict(X1_test)\n",
    "\n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf, X1_train, y1_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    \n",
    "    clf_roc_auc = roc_auc_score(y1_test, y1_pred)\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y1_test, y1_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf_roc_auc)\n",
    "\n",
    "\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "#result=logit_model.fit()\n",
    "confusion_matrix_y1 = confusion_matrix(y1_test, y1_pred)\n",
    "\n",
    "\n",
    "#print(result.summary())\n",
    "print('Accuracy of classifier on test set: {:.2f}'.format(clf.score(X1_test, y1_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of classifier: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Logistic Regression Classfier:')\n",
    "print(confusion_matrix_y1)\n",
    "\n",
    "print('Classification Report for Logistic Regression Classfier:')\n",
    "print(classification_report(y1_test, y1_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code are used to evaluate model toward `Y2`. It is very similar to the code above - key difference is that `Y2` is imbalanced - so I wrote some code (under `# Begin oversampling`) to deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.6012; AUC 0.5705 \n",
      "Accuracy of classifier on test set: 0.570\n",
      "10-fold cross validation average accuracy of clf1: 0.555\n",
      "Confusion Matrix for Classfier:\n",
      "[[20 15]\n",
      " [43 57]]\n",
      "Classification Report for Classfier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.57      0.41        35\n",
      "          1       0.79      0.57      0.66       100\n",
      "\n",
      "avg / total       0.67      0.57      0.60       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    #Model building\n",
    "    clf1 = LogisticRegression()\n",
    "\n",
    "    \n",
    "    # Splitting data into testing and training\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(predictors_y2, y2, test_size=0.2, random_state=123)\n",
    "    \n",
    "    # Begin oversampling\n",
    "    oversample = pd.concat([X2_train,y2_train],axis=1)\n",
    "    max_size = oversample['Y2'].value_counts().max()\n",
    "    lst = [oversample]\n",
    "    for class_index, group in oversample.groupby('Y2'):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    X2_train = pd.concat(lst)\n",
    "    y2_train=pd.DataFrame.copy(X2_train['Y2'])\n",
    "    del X2_train['Y2']\n",
    "    \n",
    "    # fitting model on oversampled data\n",
    "    clf1.fit(X2_train, y2_train)\n",
    "    \n",
    "    y2_pred = clf1.predict(X2_test)\n",
    "    \n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf1, X2_train, y2_train, cv=kfold, scoring=scoring)\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    \n",
    "    clf1_roc_auc = roc_auc_score(y2_test, y2_pred)\n",
    "    \n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y2_test, y2_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf1_roc_auc)\n",
    "    \n",
    "    \n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "confusion_matrix_y2 = confusion_matrix(y2_test, y2_pred)\n",
    "\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf1.score(X2_test, y2_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf1: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y2)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y2_test, y2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
