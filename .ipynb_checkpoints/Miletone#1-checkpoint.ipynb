{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1\n",
    "\n",
    "This is 3 Musketeer group Milestone report. We will present the steps we have done currently and reference the cell numbers showing the code in the 'Main.ipynb\" file.\n",
    "\n",
    "We then will outline the steps needed moving forward. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Intial Setup\n",
    "Imported libraries, data as a pandas dataframe, and the data dictionary, as well as created a text file that explains the variables (as notes for ourselves)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell # 1-2; self-explanarory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data understanding.\n",
    "\n",
    "- Replaced missing values symobol '-' with NaN. Cells 3-7\n",
    "- Looked at number of missing values for each column. Cell 9.\n",
    "- df.describe() on categorical features and numeric features. Cell 10-12.\n",
    "\n",
    "Lastly, created a pandas profile object to more detailed overview of our data. Cell 13, filename = 'df_profile_report.html'\n",
    "Here is the code for that. \n",
    "   - #trying out pandas profiling\n",
    "   - #import pandas_profiling as pp\n",
    "   - #pfr = pp.ProfileReport(df)\n",
    "   - #pfr.to_file('df_profile_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Analyzing pandas profile report\n",
    "\n",
    "Went through all the results of the report and summerized findings. From these findings, we decide on which steps are needed for purposes of cleaning the dataset.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through the variables individually from the report, here are some notes about missing values, extreme values, and strategies to keep in mind moving forward.\n",
    "\n",
    "Starting with the IPO characteristics:\n",
    "- C1: 22 missing values, skewed right. Have to determine appropriate imputation method (ffill, bfill, interpolation?)\n",
    "- C2: 22 missing values, but a dummy/binary variable. can use possible ml (logistic regression) method to impute missing values.\n",
    "- C3: 36 missing values, strong skewness, strong outliers. Will have to smooth this variable's noise. \n",
    "- C4: 22 missing values, fairly normal distribution. Dealing with ratio/returns here, so shouldn't be much noise. Mean/median imputation might be useable\n",
    "- C5: 6 missing values, # shares outstanding, so range is very large; might look like outliers, but can't treat as so since it actually is true. Missing values might actually be able to look up.\n",
    "- C6: 6 mising values, # offering shares, so similar story to C5\n",
    "- C7: __72__ missing values, might be outliers at end range of values, but \"not really\" outliers. Imputing challenge.\n",
    "\n",
    "Looking at the Textual characteristics:\n",
    "- T1: 1 missing value, slightly skewed with some high outliers. Since only 1 missing value, might be appropriate to simply impute with median.\n",
    "- T2: Has minimum value of 0, which is puzzling. Highly correlated with T1 (.93). Would be appropriate to dismiss this variable.\n",
    "- T3: Has minimum value of 0, which is puzzling. Highly correlated with T2 (.95). Also would be appropriate to dismiss thi variable.\n",
    "- T4: Has minimum value of 0, which is puzzling. Highly correlated with T3 (.96). Appropriate to dismiss this variable\n",
    "- T5: 1 missing value, with one very large outlier. Will have to handle this outlier. Has a nonsensical value of -1, need to clean this. \n",
    "\n",
    "Looking at sentiment characterisitics:\n",
    "- S1: 1 missing value, slightly skewed right. Also minimum value of -1, which is nonsensical. Must handle such exceptions\n",
    "- S2: 1 missing value, poisson distribution. Some high outliers. \n",
    "- S3: 1 missing value, skewed right. Fairly \"stable\" variable; not much quirkiness.\n",
    "\n",
    "Looking at IPO Pricing:\n",
    "- P(IPO): 5 missing values, slightly skewed right. This is final IPO offering price, which may be researchable.\n",
    "- P(H): 10 missing values, but contains a value of 0, which wouldn't make sense. Also large outlier needs to be handled.\n",
    "- P(L): Almost perfectly correlating with P(H) (.99). Can be dropped AFTER making target variable calculations. \n",
    "- P(1Day): 22 missing values, also has value of 0. Need to research if values like this and in P(H) make sense. Also two large outliers. \n",
    "\n",
    "Lastly,\n",
    "- I3: 8 missing values, imputing will be need to be done manually by researching the corresponding company.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some variables have nonsensical values, like a value of -1 in T5. Thus, here is a quick summary of any nonsensical values that may arise in our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Missing Values\n",
    "* Value of -1 in T5 and S1; can't have a negative number in these columns.\n",
    "* Value of 0 in P(1Day); wouldn't make sense for a stock to cost 0$ at end of trading day.\n",
    "* Values of 0 in T2, T3, and T4, which may or may not be a error (could be there was no MD%A). \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Data cleaning.\n",
    "\n",
    "Initially, we started cleaning some of the columns with minimal missing values, such as the 'T' columns.\n",
    "Created box plots for each of the 5 'T' variables to determine which imputation method would be best. Imupted with Median. Cells 25-29.\n",
    "\n",
    "Repeated process with 'S' columns. Imputed missing values with Medain. Cells 30-34\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we started cleaning more compex columns.\n",
    "\n",
    "First column was 'I3'. For missing values, we did research using  https://www.sec.gov/edgar/searchedgar/companysearch.html webesite to manually input correct SIC code for companies with missing values in this column. Cells 19-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the last bullet, if, for some reason, there are no words and/or sentences in a MD&A, then there should also be a consistent value in the other text variabeas as well. Therefore, we need to make sure that everything is actually consistent. Check if there are any instances of:\n",
    "- more sentences than words (T1 > T2), \n",
    "- number of real words greater than number of words (T3 > T2),\n",
    "- number of long sentences greater than number of sentences (T4 >T1)\n",
    "- number of long words greater than number of words (T5 > T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
